# .env for wikibench
# -------------------------
# Harness logging / display
# -------------------------

# 1 = show debug logs (prompts, raw model output, etc.), 0 = quieter
WIKIBENCH_DEBUG=1

# 1 = enable ANSI colors in [INFO]/[WARN]/[ERROR]/[DEBUG], 0 = plain text
WIKIBENCH_COLOR=1

# ---------------------------------
# Prompt template / harness behavior
# ---------------------------------

# Path to the YAML prompt template.
# - May be absolute, or a path relative to the repo root (SCRIPT_DIR in the harness),
#   not relative to your current shell directory.
# - The harness default is `prompts/prompt.yml`, so you usually don't need to set this
#   unless you want to experiment with alternate prompt templates.
# - Used by resolve_prompt_path() in `wikibench_ollama_harness.py`.
WIKIBENCH_PROMPT_PATH=prompts/prompt.yml

# -------------
# Ollama config
# -------------

# Where the Ollama HTTP API lives; used for /api/tags model discovery,
# and recorded in the results metadata.
# Matches Ollama's default:
OLLAMA_HOST=http://127.0.0.1:11434

# -------------------------
# Pathfinder / graph tuning
# (used by wikibench_pathfinder_async.py)
# -------------------------

# Enable or disable live visualization of the search graph 
# 1 = show graph, 0 = run headless
WIKIBENCH_VIZ=1

# Maximum requests per second (used by async rate limiter) 
# Recommended: 4–10 to avoid Wikipedia throttling 
WIKIBENCH_MAX_RPS=6 

# Maximum number of concurrent HTTP requests 
# Default: 8 — increasing may improve speed but raises load 
WIKIBENCH_CONCURRENCY=8

# Target article title for navigation runs.
# If --target is not provided on the CLI, the harness will use this.
WIKIBENCH_TARGET=Adolf Hitler